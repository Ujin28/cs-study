# 운영체제

## 키워드

**운영체제(OS)**

- 하드웨어와 응용 프로그램 사이 자원 관리
  - 안전하게 프로그램 실행 지원
  - 자원 관리를 위한 인터페이스 제공

**프로세스(Process)**

- 실행 중인 프로그램 단위
  - 코드, 데이터, 스택, 힙 등 메모리 자원을 가짐
  - 독립적인 주소 공간을 가짐

**스레드(Thread)**

- 프로세스 내 실행 단위
  - 코드, 데이터, 힙은 공유
  - 스택은 개별적으로 가짐

**멀티프로세스(Multi-Process)**

- 여러 프로세스가 독립적으로 실행됨
  - 각 프로세스는 자체 주소 공간과 자원을 가짐
  - 안전성 높음
  - 실행 속도 상대적으로 느림
  - 프로세스 간 통신(IPC, Inter-Process Communication)이 필요

**멀티스레드(Multi-Thread)**

- 한 프로세스 내에서 여러 스레드가 실행됨
  - 코드, 데이터, 힙 공유
  - 스택은 개별적
  - 실행 속도 빠름
  - race condition 등 동기화 문제 발생 가능
  - 동기화 기법(Critical Section, Mutex 등) 필요

**CPU (Central Processing Unit)**

- 연산과 제어 담당
- 프로세스/스레드 실행 관리

**메모리(Memory)**

- 프로세스 실행에 필요한 코드, 데이터, 스택, 힙 저장

**주소 공간(Address Space)**

- 프로세스가 접근 가능한 메모리 영역
  - 코드, 데이터, 스택, 힙 포함

**Context Switching(문맥 교환)**

- CPU가 한 프로세스/스레드에서 다른 것으로 전환하는 과정

  - 실행 상태 저장 및 복원
  - 비용 발생, 성능에 영향

## 질문과 답변

### 프로세스와 스레드

### 1. 프로세스와 스레드의 차이점(용도, 자원 공유 방식 등)

- **프로세스**
  - 독립적인 메모리 공간을 갖는다.
  - 다른 프로세스와 자원을 공유하지 않는다.
  - 생성/종료 비용이 크다.
  - 서로 완전히 독립된 프로그램 실행
    - ex) 브라우저, 워드, 게임 등 각각의 앱
  - 안정성이 중요할 때 사용
- **스레드**
  - 같은 프로세스 내에서 메모리를 공유한다.
  - 힙, 데이터, 코드 영역을 공유한다.
  - 스택 영역만 독립적으로 갖는다.
  - 생성/종료 비용이 작다.
  - 병렬 처리, 동시성 작업
    - ex) 웹브라우저 → 각 탭이 스레드로 동작
    - ex) 워드 프로세서 → UI 스레드, 저장 스레드, 자동 저장 스레드
  - 성능이 중요할 때, 자원 공유가 필요할 때 사용

### 2. 프로세스 끼리 어떻게 통신하는가?

- **IPC(Inter-Process Communication) 방식**

  - 운영체제에서 제공하는 방식
  - 파이프(Pipe)
    - 단방향 통신(한쪽은 쓰기, 다른 쪽은 읽기)
    - 부모-자식 프로세스 관계에서 주로 사용됨
    - ex) `ls | grep txt` 같은 리눅스 파이프 명령어
  - 메시지 큐(Message Queue)
    - 운영체제 커널이 관리하는 큐 구조
    - 여러 프로세스가 메시지를 큐에 넣고, 다른 프로세스가 꺼내는 방식
    - 동기/비동기 모두 가능, 우선순위 메시지 처리 지원
  - 공유 메모리(Shared Memory)
    - 프로세스들이 특정 메모리 영역을 함께 공유
    - 가장 빠른 IPC 방식
    - 동기화 문제 있음
  - 소켓 (Socket)
    - 네트워크 통신에 사용되지만, 같은 PC 내에서도 IPC 가능
    - TCP/UDP 기반
    - 서버-클라이언트 모델에 적합

### 3. Race Condition이란?

- 여러 프로세스/스레드가 공유 자원에 동시 접근할 때 발생하는 문제 상황
- 임계 구역(Critical section)

  - 공유 자원 접근 순서에 따라 실행 결과가 달라지는 프로그램의 코드 영역
  - 임계 구역 안에서 Race condition이 발생

- ex) 두 스레드가 같은 변수에 동시에 접근하여 값을 증가시킬 때

  ```
  x = 0

  1. 스레드 A: x 읽음 (0)
  2. 스레드 B: x 읽음 (0)
  3. A: x+1=1 저장

  x = 1

  4. B: x+1=1 저장 (A의 결과 덮어씀)

  x = 1 (예상 값 x = 2)
  ```

  - 실행 순서에 따라 결과가 달라진다.
  - 데이터 일관성이 깨진다.

### 4. Race Condition을 막는 방법

- 동기화(Synchronization)를 통해 자원 접근을 제어해야 함

- 어셈블리 언어 수준의 자원 동기화 방식

  - 뮤텍스 락(Mutex Lock, 상호 배제)

    - 동시에 하나의 스레드만 접근 가능
    - 단순하고 안전하지만 락을 얻기 위한 대기 시간으로 성능 저하 가능
    - Java의 `synchronized`: 락 획득/해제 자동 처리

      ```java
      class Account {
      private int balance = 100;

          public synchronized void deposit(int amount) {
              balance += amount; // Critical Section
          }

          public synchronized void withdraw(int amount) {
              balance -= amount; // Critical Section
          }

          public int getBalance() { return balance; }

      }
      ```

    - Java의 `ReentrantLock`: 락 획득/해제를 프로그래머가 직접 관리

      ```java
      Lock lock = new ReentrantLock();

      lock.lock();
      try {
          // critical section
      } finally {
          lock.unlock();
      }
      ```

  - 세마포어(Semaphore)
    - 여러 스레드가 동시에 접근 가능 (제한된 수)
    - 여러 개의 공유 자원을 동시에 관리

- 고급 언어에서의 자원 동기화 방식
  - 모니터
    - 객체 단위 임계 구역 보호
    - 조건에 따른 스레드 대기/신호 가능

### 5. 다중 CPU일 때 동시 처리 가능한 것은 프로세스 수인가, 스레드 수인가?

- 프로세스도 메인 스레드를 가지므로 둘 다 가능함
- 궁극적으로 **스레드 수**이다.
  - CPU 코어마다 하나의 스레드가 동시 실행
  - 프로세스는 스레드의 집합
  - 4코어 CPU에서는 최대 4개의 스레드가 동시 실행 가능

### 6. 멀티스레드를 사용하는 이유는 무엇인가?

- 성능 향상

  - 병렬 처리로 작업 속도가 빨라진다.
  - CPU 활용도가 높아진다.
  - 컨텍스트 스위칭 비용이 프로세스보다 적다.
    - 컨텍스트 스위칭: 운영체제가 CPU에서 실행 중인 작업(프로세스나 스레드)을 다른 작업으로 교체하는 과정
    - 스레드에서는 같은 주소 공간을 공유
    - 교체가 필요 없거나 적음

- 자원 공유
  - Heap 영역을 이용하여 데이터를 주고받을 수 있다.
  - 프로세스 간 통신보다 빠르다.
- 응답성 향상
  - UI 스레드와 작업 스레드를 분리할 경우 반응성이 좋아진다.

### 7. 멀티스레드에서 Critical Section 동기화 기법이란 무엇인가?

- Critical Section
  - 병렬적 실행에서, 프로세스 코드 중 공유 data에 접근하는 부분
- 동기화는 공유 자원에 접근하는 프로세스를 제어하여 안정성을 보장하는 기법이다.
- 어떤 타이밍에 Critical Section의 코드를 실행중인 프로세스는 단 하나뿐이어야한다.
- 만약 두 개 이상의 프로세스가 Critical Section의 코드를 실행중이라면 Race Condition(경쟁 조건) 이 발생한다.

### 8. 프로세스 스케줄링이란?

- CPU를 할당하는 방법(CPU 스케줄링)
  - CPU가 여러 프로세스 중 어떤 것을 언제 실행할지 순서를 결정
  - 목표
    - 처리량(Throughput) 증가
    - 응답 시간(Response Time) 최소화
    - 공정성 보장

### 9. 프로세스 스케줄링 방식

- **선점형(Preemptive) 스케줄링**

  - CPU를 이미 실행 중인 프로세스에서 강제로 빼앗아 다른 프로세스에게 할당 가능
  - 장점
    - 높은 우선순위를 가진 프로세스들이 빠른 처리를 요구하는 시스템에서 유용함
    - 응답시간이 비교적 빠르다.
    - 대화식 시스템에 적합하다.
  - 단점
    - 나중에 들어오는 프로세스들이 높은 우선순위를 가지는 경우, 잦은 context switching으로 인한 오버헤드 발생
  - 대표 알고리즘
    - **SRT (Shortest Remaining Time First)**
      - SJF의 선점형 방식
      - 남은 CPU 처리 시간이 가장 짧은 프로세스가 우선 실행
      - CPU 처리 시간이 긴 프로세스인 경우, 기아 상태 발생 가능
    - **라운드 로빈(RR: Round Robin)**
      - 시간 단위(Time Quantum)로 CPU를 할당하여 응답 시간 예측 가능
      - Time Quantum 길면 FCFS와 유사, 짧으면 Context Switching 오버헤드 증가
      - Ready Queue는 원형 큐로 동작

- **비선점형(Non-Preemptive) 스케줄링**

  - 프로세스가 자발적으로 CPU를 반납할 때까지 실행
  - Aging 기법
    - Ready Queue에 머무르는 시간에 따라 우선순위를 높여주면 우선순위가 낮은 프로세스의 기아 상태를 방지할 수 있다.
  - 장점
    - 응답시간을 예상할 수 있다.
    - 모든 프로세스에 대한 요구를 공정하게 처리한다.
  - 단점
    - 짧은 작업을 수행하는 프로세스 앞에 긴 작업을 수행하는 프로세스가 있는 경우 평균 대기시간이 길어짐
  - 대표 알고리즘

    - **FCFS (First Come First Served)**
      - CPU를 먼저 요청한 순서대로 할당(FIFO)
      - 긴 CPU 처리 시간을 가진 프로세스가 CPU를 독점하면, 평균 대기시간이 길어짐
    - **SJF (Shortest Job First)**
      - CPU 처리 시간이 짧은 프로세스를 우선 실행
      - 평균 대기시간이 짧아짐
      - CPU 처리 시간이 긴 프로세스인 경우, 기아 상태 발생 가능
    - **Priority Scheduling**
      - 우선순위가 높은 프로세스 우선 실행
      - 우선순위 동일 시 선입선처리(FCFS)
      - 우선순위가 낮은 프로세스인 경우, 기아 상태 발생 가능(예: 대화형은 RR, 배치형은 FCFS)

  - 큐 사용
    - **Multi-Level Queue (MLQ, 다단계 큐)**
      - 프로세스를 여러 큐로 나눠 관리 (예: 상호작용형 > 배치형 > 시스템 프로세스)
      - 큐 간 우선순위가 고정
      - 각 큐 마다 다른 스케줄링 알고리즘 적용 가능
    - **Multi-Level Feedback Queue (MLFQ, 다단계 피드백 큐)**
      - 프로세스의 실행 시간/행동에 따라 동적으로 큐를 옮김
      - 짧은 작업은 빨리 끝내고, 긴 작업은 점점 낮은 큐로 밀려남
      - 각 큐 마다 다른 스케줄링 알고리즘 적용 가능(예: 상위 큐는 선점형 RR, 하위 큐는 FCFS)

### 10. Context Switching이 이루어지는 과정

- PCB에 현재 프로세스 상태 저장
  - PCB(Process Control Block): 운영체제가 각 프로세스의 상태와 정보를 관리하기 위해 사용하는 자료 구조
  - 레지스터, 프로그램 카운터, 스택 포인터 저장
- 새 프로세스의 상태를 PCB에 복원
  - 프로그램 카운터 세팅 후 실행 재개

### 메모리

### 1. 힙(Heap)의 역할, 사용 방식

- 동적 메모리 할당 영역이다.
  - **동적 메모리**
    - 프로그램 실행 중에 크기가 결정되는 데이터
  - `malloc`, `new`등으로 할당
  - `free`, `delete`등으로 해제
- **특징**
  - 크기가 가변적이다.
  - 할당/해제가 자유롭다.
  - 접근 속도가 상대적으로 느리다.
  - 메모리 누수 위험이 있다.

### 2. 스택(Stack) 오버플로우란 무엇이고, 발생 시 운영체제에서 어떤 일을 하는지?

- 스택 영역의 메모리가 부족해지는 현상이다.
  - 무한 재귀 호출시 발생한다.
  - 지역 변수가 차지하는 영역이 커지는 경우 발생한다.
- **운영체제의 처리**
  - 세그멘테이션 오류(Segmentation Fault) 발생
  - 프로세스 강제 종료
  - 에러 메시지 출력

### 3. 가상 메모리의 주소 매핑 방식

- 가상 주소(CPU)를 물리 주소(RAM)로 변환한다.
  - **페이징**: 고정 크기 블록으로 분할
  - **세그멘테이션**: 가변 크기 논리 단위로 분할
- MMU(Memory Management Unit)가 물리 주소를 논리 주소로 변환함
- **페이지 테이블**을 통해 매핑 정보를 관리함

### 4. 동적, 정적, 스택 메모리의 특징

- **동적 메모리(Heap)**

  - 런타임에 크기가 결정된다.
  - 수동으로 할당/해제해야 한다.
  - 가장 유연하지만 관리가 복잡하다.

  ```java
  String str = new String("Hello Heap"); // GC가 회수할 때까지 유지(Java)
  ```

- **정적 메모리**

  - 컴파일 시점에 크기가 결정된다.
  - 프로그램 시작 시 할당된다.
  - 전역 변수로 선언하면 전역 접근이 가능하다.
  - 프로그램 종료까지 유지된다.
  - 누수되지 않으며 초기화가 보장된다.

  ```java
  static int count = 0; // 프로그램 종료 시까지 유지(Java)
  ```

- **스택 메모리**

  - 함수 호출/반환시 자동 할당/해제된다.
  - 지역 변수, 매개변수가 저장된다.
  - 후입선출(LIFO) 방식으로 관리된다.
  - 깊은 재귀 호출 시 스택 오버플로우가 발생한다.

  ```java
  public void example() {
      int localVar = 10; // 메서드 끝나면 해제(Java)
  }
  ```

### 5. 2차 저장장치는 무엇인가?

- 컴퓨터의 주기억장치(RAM) 외부에서 데이터를 영구적으로 저장하는 장치
- 전원이 꺼져도 데이터가 유지된다.
- **특징**
  - 비휘발성 저장장치이다.
  - 메인 메모리(RAM)보다 느리다.
  - 용량에 비해 비용이 저렴하다.
- **종류**
  - **HDD(Hard Disk Drive)**
    - 기계적 방식 (회전/헤드 이동)
    - 속도 느림, 비용 저렴, 용량 큼
    - 데이터 저장에 적합
  - **SSD(Solid State Drive)**
    - 반도체 기반의 비휘발성 저장장치
    - 기계적 부품 없이 전자적으로 읽고 씀
    - 속도 빠름, 전력 소모 적음, 비용 높음
    - 속도가 중요한 데이터 저장에 적합 (운영체제, 게임, 작업프로젝트 등)
  - **광학 드라이브**: CD, DVD, Blu-ray
    - 용량이 작고, 속도가 느림
    - 미디어, 설치용 소프트웨어 저장에 적합
